{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGEMM for KNL\n",
    "\n",
    "Reproduction of:\n",
    "Lim, R., Lee, Y., Kim, R. et al. Cluster Comput (2018) 21: 1785. https://doi.org/10.1007/s10586-018-2810-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'BOAST'\n",
    "include BOAST\n",
    "set_lang(C)\n",
    "set_array_start(0)\n",
    "type_map = { 4 => NArray::SFLOAT, 8 => NArray::FLOAT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro-kernel\n",
    "### Definition\n",
    "The first step is implementing an efficient micro-kernel\n",
    "The micro-kernel update a block of $C$ of size $[mr, nr]$ noted $\\widehat{C}$ using a block of $A$ of size $[mr, kb]$ noted $\\widehat{A}$ and a block of $B$ of size $[kb, nr]$ noted $\\widehat{B}$. $\\widehat{A}$ is stored in column major order while $\\widehat{C}$ and $\\widehat{B}$ are stored in row major order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_kernel(vector_length: 4, nr: nil, mr: nil, kb: nil)\n",
    "  raise \"nr must be a multiple of vector_length!\" unless nr % vector_length == 0\n",
    "  nvec = nr / vector_length\n",
    "  register_number = mr * nvec + nvec\n",
    "  puts \"Using #{register_number} registers...\"\n",
    "  \n",
    "  ah = Real :ah, dim: [Dim(mr), Dim(kb)], dir: :in, restrict: true\n",
    "  bh = Real :bh, vector_length: vector_length, dim: [Dim(nvec), Dim(kb)], dir: :in, restrict: true\n",
    "  ch = Real :ch, vector_length: vector_length, dim: [Dim(nvec), Dim(mr)], dir: :inout, restrict: true\n",
    "  inp = Procedure(\"inp_#{vector_length}_#{nr}_#{mr}_#{kb}\", [ah, bh, ch]) {\n",
    "    regs = (0...nvec).collect { |n|\n",
    "      (0...mr).collect { |m|\n",
    "        Real :\"reg_#{n}_#{m}\", vector_length: vector_length, register: true\n",
    "      }\n",
    "    }\n",
    "    regs_b = (0...nvec).collect { |n|\n",
    "      Real :\"regs_b_#{n}\", vector_length: vector_length, register: true\n",
    "    }\n",
    "    decl *regs.flatten\n",
    "    decl *regs_b\n",
    "    (0...mr).collect { |m|\n",
    "      (0...nvec).collect { |n|\n",
    "        pr regs[n][m] === ch[n, m]\n",
    "      }\n",
    "    }\n",
    "    i = Int :i\n",
    "    decl i\n",
    "    pr For(i, 0, kb - 1) {\n",
    "      (0...nvec).each { |n|\n",
    "        pr regs_b[n] === bh[n, i]\n",
    "      }\n",
    "      (0...mr).each { |m|\n",
    "        (0...nvec).each { |n|\n",
    "          pr regs[n][m] === FMA(Set(ah[m, i], regs_b[0]), regs_b[n], regs[n][m])\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    (0...mr).collect { |m|\n",
    "      (0...nvec).collect { |n|\n",
    "        pr ch[n, m] === regs[n][m]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  inp.ckernel(includes: \"immintrin.h\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length = 4\n",
    "mr = 4\n",
    "nr = 12\n",
    "kb = 480\n",
    "nvec = nr / vector_length\n",
    "type = type_map[get_default_real_size]\n",
    "alignment = get_default_real_size*vector_length\n",
    "a = NMatrix::new(type, kb, mr).random!\n",
    "b = NMatrix::new(type, nr, kb).random!\n",
    "c = NMatrix::new(type, nr, mr).random!\n",
    "\n",
    "ah = ANArray::new(type, alignment, mr, kb)\n",
    "bh = ANArray::new(type, alignment, vector_length, nvec, kb)\n",
    "ch = ANArray::new(type, alignment, vector_length, nvec, mr)\n",
    "c_ref = ANArray::new(type, alignment, vector_length, nvec, mr)\n",
    "ah[true, true] = a.transpose(1,0)[true, true]\n",
    "bh[true, true, true] = b.reshape(vector_length, nvec, kb)[true, true, true]\n",
    "ch[true, true, true] = c.reshape(vector_length, nvec, mr)[true, true, true]\n",
    "c_ref[true, true, true] = (a*b + c).reshape(vector_length, nvec, mr)[true, true, true]\n",
    "\n",
    "p = micro_kernel(vector_length: vector_length, mr: mr, nr: nr, kb: kb)\n",
    "p.run(ah, bh, ch)\n",
    "max_error = (ch - c_ref).abs.max\n",
    "raise \"Computation error!\" if max_error > 1e-8\n",
    "puts \"Success!\"\n",
    "nil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.run(ah, bh, ch)\n",
    "repeat_inner = 100\n",
    "res = 1000.times.collect {\n",
    "  p.run(ah, bh, ch, repeat: repeat_inner)\n",
    "}\n",
    "best = res.min { |r1, r2|\n",
    "  r1[:duration] <=> r2[:duration]\n",
    "}\n",
    "perf = mr * nr * kb * 2 / (best[:duration] * 1e9 / repeat_inner )\n",
    "puts \"time: #{best[:duration] / repeat_inner} s, GFlops: #{perf}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium Kernel\n",
    "### Definition\n",
    "The medium kernel works using blocks of intermediate size. The medium kernel updates a block of $C$ of size $[kb,n]$ noted $\\widetilde{C}$ using a block of $A$ of size $[mb,kb]$ noted $\\widetilde{A}$ and a block of $B$ of of size $[kb,n]$ noted $\\widetilde{B}$. $\\widetilde{A}$ is stored as $mb/mr$ consecutive blocks of size $[mr, kb]$ ($\\widehat{A}$) in column major order while $\\widetilde{C}$ is stored as $(mb/mr)*(n/nr)$ consecutive blocks of size $[mr,nr]$ ($\\widehat{C}$) in row major order and $\\widetilde{B}$ is stored as $n/nr$ blocks of size $[kb, nr]$ ($\\widehat{B}$) in row major order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medium_kernel(vector_length: 4, mb: nil, nr: nil, mr: nil, kb: nil)\n",
    "  raise \"nr must be a multiple of vector_length!\" unless nr % vector_length == 0\n",
    "  raise \"mr must be a multiple of mb!\" unless mb % mr == 0\n",
    "  nvec = nr / vector_length\n",
    "  nblocka = mb / mr\n",
    "\n",
    "  inp = micro_kernel(vector_length: vector_length, nr: nr, mr: mr, kb: kb)\n",
    "  \n",
    "  #n = Int :n, dir: :in\n",
    "  nblockn = Int :nblockn, dir: :in #n / nr\n",
    "  at = Real :at, dim: [Dim(mr), Dim(kb), Dim(nblocka)], dir: :in, restrict: true\n",
    "  bt = Real :bt, vector_length: vector_length, dim: [Dim(nvec), Dim(kb),  Dim(nblockn)], dir: :in, restrict: true\n",
    "  ct = Real :ct, vector_length: vector_length, dim: [Dim(nvec), Dim(mr),  Dim(nblocka), Dim(nblockn)], dir: :inout, restrict: true\n",
    "  medp = Procedure( \"medp_#{vector_length}_#{mb}_#{nr}_#{mr}_#{kb}\", [nblockn, at, bt, ct] ) {\n",
    "    jr = Int :jr\n",
    "    ir = Int :ir\n",
    "    decl jr, ir\n",
    "    pr For(jr, 0, nblockn - 1) {\n",
    "      pr For(ir, 0, nblocka - 1) {\n",
    "        pr inp.procedure.call(at[0, 0, ir].address, bt[0, 0, jr].address, ct[0, 0, ir, jr].address)\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  k = CKernel::new(includes: \"immintrin.h\") {\n",
    "    pr inp.procedure\n",
    "    pr medp\n",
    "  }\n",
    "  k.procedure = medp\n",
    "  k\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length = 4\n",
    "mr = 4\n",
    "nr = 12\n",
    "nblocka = 18\n",
    "mb = mr * nblocka\n",
    "kb = 480\n",
    "nblockn = 1024\n",
    "n  = nr * nblockn\n",
    "nvec = nr / vector_length\n",
    "\n",
    "type = type_map[get_default_real_size]\n",
    "alignment = get_default_real_size*vector_length\n",
    "a = NMatrix::new(type, kb, mb).random!\n",
    "b = NMatrix::new(type, n, kb).random!\n",
    "c = NMatrix::new(type, n, mb).random!\n",
    "\n",
    "at = ANArray::new(type, alignment, mr, kb, nblocka)\n",
    "bt = ANArray::new(type, alignment, vector_length, nvec, kb, nblockn)\n",
    "ct = ANArray::new(type, alignment, vector_length, nvec, mr, nblocka, nblockn)\n",
    "c_ref = ANArray::new(type, alignment, vector_length, nvec, mr, nblocka, nblockn)\n",
    "at[true, true, true] = a.reshape(kb, mr, nblocka).transpose(1, 0, 2)[true, true, true]\n",
    "bt[true, true, true, true] = b.reshape(vector_length, nvec, nblockn, kb)\n",
    "                              .transpose(0, 1, 3, 2)[true, true, true, true]\n",
    "ct[true, true, true, true, true] = c.reshape(vector_length, nvec, nblockn, mr, nblocka)\n",
    "                              .transpose(0, 1, 3, 4, 2)[true, true, true, true, true]\n",
    "c_ref[true, true, true, true, true] = (a*b + c).reshape(vector_length, nvec, nblockn, mr, nblocka)\n",
    "                                         .transpose(0, 1, 3, 4, 2)[true, true, true, true, true]\n",
    "\n",
    "p = medium_kernel(vector_length: vector_length, mb: mb, mr: mr, nr: nr, kb: kb)\n",
    "p.run(nblockn, at, bt, ct)\n",
    "max_error = (ct - c_ref).abs.max\n",
    "raise \"Computation error!\" if max_error > 1e-8\n",
    "puts \"Success!\"\n",
    "nil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.run(nblockn, at, bt, ct)\n",
    "repeat_inner = 10\n",
    "res = 10.times.collect {\n",
    "  p.run(nblockn, at, bt, ct, repeat: repeat_inner)\n",
    "}\n",
    "best = res.min { |r1, r2|\n",
    "  r1[:duration] <=> r2[:duration]\n",
    "}\n",
    "perf = mb * n * kb * 2 / (best[:duration] * 1e9 / repeat_inner )\n",
    "puts \"time: #{best[:duration] / repeat_inner} s, GFlops: #{perf}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Kernel\n",
    "### Definition\n",
    "The large kernel uses matrix of any size. In our implementation we will consider the matrix to be already transformed. The original matrices are $C$ of size $[m,n]$, $A$ of size $[m,k]$ and $B$ of size $[k,n]$. The layout used here are: $C$ is stored as $m/mb$ blocks of $\\widetilde{C}$, $A$ is stored as $(k/kb)*(m/mb)$ blocks of $\\widetilde{A}$ and $B$ is stored as $(k/kb)$ blocks of $\\widetilde{B}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_kernel(vector_length: 4, mb: nil, nr: nil, mr: nil, kb: nil)\n",
    "  raise \"nr must be a multiple of vector_length!\" unless nr % vector_length == 0\n",
    "  raise \"mr must be a multiple of mb!\" unless mb % mr == 0\n",
    "  \n",
    "  inp = micro_kernel(vector_length: vector_length, nr: nr, mr: mr, kb: kb)\n",
    "  medp = medium_kernel(vector_length: vector_length, mb: mb, nr: nr, mr: mr, kb: kb)\n",
    "  \n",
    "  #m = Int :m, dir: :in\n",
    "  #n = Int :n, dir: :in\n",
    "  #k = Int :k, dir: :in\n",
    "  nvec = nr / vector_length\n",
    "  nblockm = Int :nblockm, dir: :in #m / mb\n",
    "  nblocka = mb / mr\n",
    "  nblockn = Int :nblockn, dir: :in #n / nr\n",
    "  nblockk = Int :nblockk, dir: :in #k / kb\n",
    "  a = Real :a, dim: [Dim(mr), Dim(kb), Dim(nblocka), Dim(nblockm), Dim(nblockk)], dir: :in, restrict: true\n",
    "  b = Real :b, vector_length: vector_length, dim: [Dim(nvec), Dim(kb), Dim(nblockn), Dim(nblockk)], dir: :in, restrict: true\n",
    "  c = Real :c, vector_length: vector_length, dim: [Dim(nvec), Dim(mr), Dim(nblocka), Dim(nblockn), Dim(nblockm)], dir: :inout, restrict: true\n",
    "  larp = Procedure( \"larp_#{vector_length}_#{mb}_#{nr}_#{mr}_#{kb}\", [nblockm, nblockn, nblockk, a, b, c] ) {\n",
    "    p = Int :p\n",
    "    i = Int :i\n",
    "    decl p, i\n",
    "    pr OpenMP::Parallel(default: :shared) {\n",
    "    pr OpenMP::Single() {\n",
    "    pr For(p, 0, nblockk - 1) {\n",
    "      pr For(i, 0, nblockm - 1) {\n",
    "        pr OpenMP::Task(depend: {in: [a[:all, :all, :all, i, p],\n",
    "                                      b[:all, :all, :all, p]],\n",
    "                                 inout: [c[:all, :all, :all, :all, i]] } ) {\n",
    "          pr medp.procedure.call(nblockn, a[0, 0, 0, i, p].address, b[0, 0, 0, p].address, c[0, 0, 0, 0, i].address)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  k = CKernel::new(includes: \"immintrin.h\") {\n",
    "    pr inp.procedure\n",
    "    pr medp.procedure\n",
    "    pr larp\n",
    "  }\n",
    "  k.procedure = larp\n",
    "  k\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length = 4\n",
    "mr = 4\n",
    "nr = 12\n",
    "nblocka = 18\n",
    "mb = mr * nblocka\n",
    "kb = 480\n",
    "nblockn = 128\n",
    "n  = nr * nblockn\n",
    "nvec = nr / vector_length\n",
    "nblockm = 21\n",
    "m = mb * nblockm\n",
    "nblockk = 3\n",
    "k = kb * nblockk\n",
    "\n",
    "type = type_map[get_default_real_size]\n",
    "alignment = get_default_real_size*vector_length\n",
    "a = NMatrix::new(type, k, m).random!\n",
    "b = NMatrix::new(type, n, k).random!\n",
    "c = NMatrix::new(type, n, m).random!\n",
    "\n",
    "puts \"a: #{m}x#{k} (#{m*k*get_default_real_size/(1e9)} GiB)\"\n",
    "puts \"b: #{k}x#{n} (#{k*n*get_default_real_size/(1e9)} GiB)\"\n",
    "puts \"c: #{m}x#{n} (#{m*n*get_default_real_size/(1e9)} GiB)\"\n",
    "\n",
    "ap = ANArray::new(type, alignment, mr, kb, nblocka, nblockm, nblockk)\n",
    "bp = ANArray::new(type, alignment, vector_length, nvec, kb, nblockn, nblockk)\n",
    "cp = ANArray::new(type, alignment, vector_length, nvec, mr, nblocka, nblockn, nblockm)\n",
    "c_ref = ANArray::new(type, alignment, vector_length, nvec, mr, nblocka, nblockn, nblockm)\n",
    "ap[true, true, true, true, true] = a.reshape(kb, nblockk, mr, nblocka, nblockm)\n",
    "                                    .transpose(2, 0, 3, 4, 1)[true, true, true, true, true]\n",
    "bp[true, true, true, true, true] = b.reshape(vector_length, nvec, nblockn, kb, nblockk)\n",
    "                                    .transpose(0, 1, 3, 2, 4)[true, true, true, true, true]\n",
    "cp[true, true, true, true, true, true] = c.reshape(vector_length, nvec, nblockn, mr, nblocka, nblockm)\n",
    "                                          .transpose(0, 1, 3, 4, 2)[true, true, true, true, true, true]\n",
    "c_ref[true, true, true, true, true, true] = (a*b + c).reshape(vector_length, nvec, nblockn, mr, nblocka, nblockm)\n",
    "                                                     .transpose(0, 1, 3, 4, 2)[true, true, true, true, true, true]\n",
    "push_env(use_vla: true) {\n",
    "  p = large_kernel(vector_length: vector_length, mb: mb, mr: mr, nr: nr, kb: kb)\n",
    "  p.build(openmp: true)\n",
    "}\n",
    "p.run(nblockm, nblockn, nblockk, ap, bp, cp)\n",
    "  \n",
    "max_error = (cp - c_ref).abs.max\n",
    "raise \"Computation error!\" if max_error > 1e-8\n",
    "puts \"Success!\"\n",
    "nil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.run(nblockm, nblockn, nblockk, ap, bp, cp)\n",
    "res = 100.times.collect {\n",
    "  p.run(nblockm, nblockn, nblockk, ap, bp, cp)\n",
    "}\n",
    "best = res.min { |r1, r2|\n",
    "  r1[:duration] <=> r2[:duration]\n",
    "}\n",
    "perf = m * n * k * 2 / (best[:duration] * 1e9)\n",
    "puts \"time: #{best[:duration]} s, GFlops: #{perf}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 2.5.1",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "2.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
