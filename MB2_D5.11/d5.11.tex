\documentclass[11pt, a4paper, twoside]{montblanc2}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{color}
\usepackage{xspace}
\usepackage{listings}
\usepackage{graphics}

\def\cmake{\textsc{CMake}\xspace}
\def\lua{\textsc{Lua}\xspace}
\def\ruby{\textsc{Ruby}\xspace}
\def\dd{\textsc{DwarfDump}\xspace}
\def\elfutils{\textsc{ElfUtils}\xspace}

\urlstyle{sf}

\definecolor{bluelst}{rgb}{0.4,0.8,1.0}
\definecolor{greenlst}{rgb}{0.25,0.50,0}

\lstdefinestyle{C}{
  language=C,
  basicstyle=\small\sffamily,
  frame=single,
  rulecolor=\color{bluelst},
  commentstyle=\color{greenlst}\textit,
  keywordstyle=\bfseries,
  breaklines=true,
  numbers=left,
  numberstyle=\tiny,
  numbersep=5pt,
  tabsize=4
}

\lstdefinestyle{BOAST}{
  language=Ruby,
  basicstyle=\small\sffamily,
  frame=single,
  rulecolor=\color{bluelst},
  commentstyle=\color{greenlst}\textit,
  keywordstyle=\bfseries,
  breaklines=true,
  numbers=left,
  numberstyle=\tiny,
  numbersep=5pt,
  tabsize=2,
  morekeywords={BOAST, pr, decl, opn, close}
}

\begin{document}
\devnum{[5.11]}
\title{[MAQAO in BOAST]}
\version{[0.1]}
\deadline{[2017/01/16]}
\level{[PU]}
\nature{[O]}
\authors{Olivier Aumage (Inria) and Brice Videau (CNRS)}
\contributors{} % {Name (PARTNER), Name (PARTNER), Name (PARTNER)}
\reviewers{} % {Name (PARTNER), Name (PARTNER), }
\keywords{[analysis, autotuning, performance]}

\maketitle

\begin{changelog}
\change{0.1}{Initial version of D5.11}
\end{changelog}

\frontmatter

\begin{executive}

  This document presents the integration of MAQAO, a binary-level code analysis 
  framework, with BOAST, an automatic performance tuning framework for 
  meta-programming and optimizing computing kernels. From source meta-kernels 
  written in the \ruby language, BOAST generates multiple versions, in various 
  target languages, optionally applying optimization transformations and 
  strategies, and exploring the space of compiler flags combinations, to 
  discover the most effective kernel tuning parameters. MAQAO offers a 
  scriptable framework to disassemble kernel binaries, explore binary 
  instruction flows, register-level data dependencies, program control 
  structures, to patch, re-assemble and instrument kernel binaries for tracing data 
  access patterns, and to process them from custom analyzers written in the \lua 
  language. The purpose of this integration work is to build on the 
  complementarity of these two environments by enabling MAQAO to process binary 
  kernels generated by BOAST. The document exposes this complementarity by 
  describing the abilities and features of the two frameworks. A general view of 
  the integration layout and functional organisation is then presented. 
  Implementations requirements, issues and solutions are discussed extensively, 
  followed by example cases. Finally, the document discusses on going works and future 
  plans beyond the frameworks integration.

\end{executive}

\section{Introduction}\label{sec:intro}

Optimizing computing kernels involves acting on a large number of parameters and 
knobs, from the high level algorithm and data structure layout decisions to the 
compile-time options and optimization flags. Exploring such a large 
combinatorial space systematically and efficiently is cumbersome at best, and 
often impractical even for skilled developers. The BOAST framework relieves the 
programmer from most of this burden, by enabling he/she to write a meta-kernel 
from a high level point-of-view. This meta-kernel is then automatically 
instantiated on demand by BOAST, with full control over optimization strategies, 
both on the kernel source instantiation side, and on the compiler 
parameterization side. Leveraging the strengths of the \ruby language together with 
some clever framework design, BOAST can scan through a large set of optimization 
combinations to select the one most effective on the platform, with the compiler 
tool chain brands and versions available, and with the right mix of compiler 
options.

Exploring the binaries generated by the compiler may also give clues on how to 
optimize the source code, by finding potential performance hindrances in the 
instruction flow, in inter-loop dependencies, in data access patterns inferred 
from the assembly code or observed from execution traces. The MAQAO framework aims 
at providing the developer with an environment to design custom binary 
exploration scripts, to scrutinize computation kernels at the lowermost level. 
Since BOAST acts at the code generation side and MAQAO works at the binary observation 
side, the complementarity of both frameworks naturally offers a significant 
potential for synergy. The purpose of the present document is to present the 
integration effort to make both tools able to work together, as well as the 
resulting combined framework design.

This deliverable document is organized as follows. It first gives an overview of 
the context of this work in Section~\ref{sec:context}, by detailing both 
frameworks' characteristics, capabilities and usage. Then, 
Section~\ref{sec:integration} exposes the big picture for the integration from a 
functional point of view, together with files and information flows. It also 
explains how the integrated ``composite'' framework made of BOAST and MAQAO can 
be used by a programmer. Section~\ref{sec:implementation} discusses 
implementation requirements, issues and solutions adopted to build the 
integrated framework. Section~\ref{sec:examples} gives some use examples for the 
framework, both on a micro-kernel, and on a kernel extracted from
BigDFT~\cite{genovese:bigdft:jcp:2008}, an ab-initio nanosimulation code
written at CEA and part of Project Mont-Blanc~2's target applications.
Section~\ref{sec:conclusion} concludes this document, and exposes upcoming and
future works to build on Deliverable D5.11 achievements.

\section{Context}\label{sec:context}

This section presents the two frameworks BOAST, developed at CNRS, and MAQAO, 
developed at Inria, whose integration will be discussed and reviewed in the 
remainder of this document.

\subsection{BOAST}
%\begin{itemize}
%  \item General presentation of BOAST
%  \item Purpose, capabilities, usage
%\end{itemize}

\input{boast.tex}

\subsection{MAQAO}
%\begin{itemize}
%  \item General presentation of MAQAO
%  \item Purpose, capabilities, usage
%\end{itemize}

\subsubsection{Presentation}
MAQAO, the Modular Assembly Quality Analyzer and Optimizer, is a performance analysis and processing 
tool working at the level of compiled, binary code. It was initially developed at the University of 
Versailles in France, and has been partially developed at Inria in Bordeaux as well, since around 
2010. While primarily focused on Intel processors (x86-64, xeon phi, and even Itanium), it was 
ported on the ARM architecture as part of Mont-Blanc~2 task D5.3's work, and delivered as 
Deliverable~D5.4. The MAQAO tool presents itself as an extensible framework for binary code 
processing. It is a made of a C-language low-level core set of libraries, and a high-level set of 
wrappers making the framework scriptable in the language \lua using the embedded interpretor. 

The core libraries of MAQAO enable the fundamental operations to disassemble a binary file, modify 
its assembly instructions (operation designated as 'patching'), and re-assemble the modified binary. 
Possible instruction modifications include moving/inserting/suppressing code blocks, inserting 
function calls, or operations designated as 'instrumentation,' where some sets of instructions are 
both moved and modified, such as that function call is made every time such instructions are called, 
before executing the instrumented instructions themselves. Core services also include foundational 
capabilities such as building call graphs, control flow graphs and instruction 
level dependence graphs from the disassembled binary functions.

A set of \lua-to-C wrapper routines implement the transition between the C~core and the \lua 
services. These routines enable to manipulate relevant assembly objects such as binary files, 
functions, basic instruction blocks, individual instructions, instruction operands, loops and 
labels. 

On top of those transitional routines, special-purpose processing modules can be implemented in \lua 
to perform high level operations such as analysis, tracing and hinting. In particular, tracing 
involves instrumenting every memory reference in the studied kernel with calls to the memory access 
accounting routine in the MAQAO Trace Library (MTL), which monitors every memory address referenced 
within the kernel routine during an execution, and generates a compressed trace of the memory 
references. The trace can then be further processed to output memory access patterns as human 
readable algebraic expressions.

\subsubsection{Usage}

The MAQAO framework version developed in Bordeaux is very much targeted at an experienced audience, 
and, as a note of warning, it may lack the user friendliness commonly found in mature academic and 
commercial programming tools. It is aimed at expert users desirous to dig further into the binary 
kernel code produced by their compiler, and build their own, custom analysis strategies.
This section presents MAQAO from a functional point-of-view, and specifies usage for the most common
operations.

\paragraph{Requirements and Installation}

MAQAO's C language core mandatorily requires \cmake version~2.8.8 or above, a C compiling toolchain 
and Make. The \lua layers directly make use of the embedded \lua distribution. Moreover, MAQAO 
analysis scripts may leverage the command-line tool \dd to process debugging informations and 
symbols in compiled objects files when available, while \dd itself relies on the availability of an 
\elfutils distribution. Supported binary objects and executables to be processed by MAQAO must 
follow the ELF format specification and System V general ABI specification, and be generated for the 
ARM architecture, while optional debugging information must follow the DWARF-2 format. Support for 
ARM's Thumb instruction sets is limited to disassembly only.

Building MAQAO involves running \cmake followed by the \verb|make| command, after untaring the 
distribution or checking it out from the development repository:

\begin{verbatim}
$ tar zxf maqao.tar.gz
$ cd MAQAO
$ mkdir build
$ cd build
$ cmake -DARCHS=arm -DSTRIP=false ..
$ make
\end{verbatim}

No install step is required. MAQAO's executable is produced in \verb|MAQAO/bin| and MAQAO's 
libraries are placed in the \verb|MAQAO/lib| directory. MAQAO's \verb|/bin| and \verb|/lib|
directories should be added to \verb|PATH| and \verb|LD_LIBRARY_PATH| environment variables 
respectively. Environment variable \verb|MAQAO| should be set to MAQAO's top directory for 
convenience, and is assumed to be set accordingly in the remainder of the document.

\paragraph{Disassemble}

Disassembling and low level assembly management is handled by MAQAO's Madras module. Every MAQAO 
module is accessed by specifying its name as first argument of MAQAO. Module's arguments are then 
prepended after the module name. Binary disassembled listings can be obtained using Madras as 
follows:

\begin{verbatim}
$ maqao madras -d <BINARY>
...
bf4c <s1111>:
 [...] f0 45 2d e9  0xbf4c push   {r4, r5, r6, r7, r8, sl, lr}; [...]
 [...] 02 8b 2d ed  0xbf50 vpush  d8; [...]
 [...] 14 d0 4d e2  0xbf54 sub    sp, sp, #20 ; [...]
 [...] 94 0d 0f e3  0xbf58 movw   r0, #64916 ; [...]
 [...] 01 00 40 e3  0xbf5c movt   r0, #1 ; [...]
...
\end{verbatim}

\paragraph{Instrument}

Instrumentation is the process of inserting probes for a set of specific
assembler instructions such that every time on of these instructions is encountered
during execution, some accounting probe function can be called to account for
that instruction occurrence. Instrumentation in MAQAO is provided by the Memory module,
to target memory referencing instructions, such as to extract memory access
patterns at run-time. The Memory module itself calls the Madras module under the
hood, to perform the low-level assembly manipulations involved.

\begin{verbatim}
$ maqao memory -i -bin=<BINARY> -f=<FUNCTION_NAME> -m=unicore -tp==<TEMP_DIR>
\end{verbatim}

Argument \verb|-i| requests instrumenting. Argument \verb|-bin| specifies the
binary executable to instrument. The MAQAO ARM port does not support
instrumenting position independent code (PIC) currently, thus the binary file
cannot be a shared library. Argument \verb|-f| specifies the function to
instrument. Argument \verb|-m| specifies the execution model. Finally, argument
\verb|-tp| specifies the directory in which the resulting instrumented binary
and its companion \lua meta-data file are generated. The actual instrumentations 
probe functions are trace recording routines from the MAQAO Trace Library (MTL).

\paragraph{Trace}

Executing the resulting instrumented kernel produces a trace file containing a 
compressed representation of the target addresses of each memory access 
instruction encountered during execution. For each instruction instrumented, the 
flow of addresses captured is compressed on-the-fly using a lossless
algorithm named \emph{Nested Loop Recognition} (NLR), designed by Ketterlin and 
Clauss~\cite{ketterlin:nlr:cgo:2008}. The trace is stored using a compact text 
file format, not meant to be read as-is by the programmer, as shown below.

\begin{footnotesize}
\begin{verbatim}
D 1 E 10 R 1 I 1 K 0 V  L P 39 L P 259 0 T 1 P 1262052 0 8 0 N N N I 2 K 0 V  L 
P 39 L P 259 0 T 1 P 3439840 0 8 0 N N N I 3 K 0 V  L P 39 L P 259 0 T 1 P 
3439852 0 8 0 N N N I 4 K 0 V  L P 39 T 1 P 3199305884 0 N N I 5 K 0 V  L P 39 T 
1 P 3199305888 0 N N I 6 K 0 V  L P 39 T 1 P 3199305892 0 N N I 7 K 0 V  L P 39 
T 1 P 3199305896 0 N N I 8 K 0 V  L P 39 L P 259 0 T 1 P 1262052 0 8 0 N N N I 9 
K 0 V  L P 39 L P 259 0 T 1 P 3439840 0 8 0 N N N I 10 K 0 V  L P 39 L P 259 0 T 
1 P 3439852 0 8 0 N N N 
\end{verbatim}
\end{footnotesize}

This intermediate format can however be processed by MAQAO's Memory module to 
produce a human-readable version of the NLR trace. The command below produces
the human-readable form of the trace from the compact trace and from the companion
\lua meta-data file generated during the instrumentation step.
 
\begin{verbatim}
$ maqao memory -d -t=<COMPACT_TRACE> -meta=<META_LUA_FILE> -tp=<TEMP_DIR>
\end{verbatim}

This human-readable version shows, for each instrumented instruction, the
corresponding thread id, the id of the loop containing the instruction as
assigned by MAQAO, and the 'instrumented instruction' id also incrementally
assigned by MAQAO. Multiple instances may exist when multiple threads invoke
the instruction.

\begin{footnotesize}
\begin{verbatim}
Info: ################################################################################
Info: ## Volume for tid = 0 loopid = 21 iid = 0
Info: ################################################################################
Info: Instance 0
Info: ###############
for i0 = 0 to 39
  for i1 = 0 to 259
    val 0x1341e4 + 8*i1

 [...]
\end{verbatim}
\end{footnotesize}

Then, following the identification information, the successive values captured
by the instrumentation are represented by as a pseudo source-code with loops and
expressions. The expressions describe the memory addresses that have been
accessed, and depend on the surrounding loop counters and loop bounds, as
detected by the NLR algorithm. The portion of trace above corresponds to the
Array \texttt{b} reference in the basic loop nest below, extracted from routine
\texttt{s111} of the TSVC benchmark
suite~\cite{maleki:vectorization:pact:2011,callahan:tsvc:sc:1988}. Array
elements in this example are 32-bit single precision floating point values. Thus, the
\texttt{8*i1} expression in the trace expresses a 2-element stride array
traversal, corresponding to the innermost loop \texttt{i} index step value in the
source code. The \texttt{i0} is not referenced in the expression, meaning the
outer loop is a repetition loop.

\lstset{style=C}
\begin{lstlisting}
/* TSVC s111 kernel */
for (int nl = 0; nl < 2*ntimes; nl++) {
	for (int i = 1; i < LEN; i += 2) {
		a[i] = a[i - 1] + b[i];
	}
}
\end{lstlisting}

Trace expressions can, however, only depend linearly on the loop counters, and
loop bounds only depend linearly on enclosing loops' counters. The memory
addresses referenced by an expression forms an union of polytopes. Thus, the
method captures the memory working-set as well as a schedule for the memory
accesses.

\paragraph{Analyze}

MAQAO's SIMD analyzer is a MAQAO module built on top of the \lua API to analyze
simdization potential in compiled kernel binaries, as well as possible issues
hindering vectorization. The SIMD analyzer module can be applied to a kernel,
using the following command:

\begin{verbatim}
export MAQAO_SA_PATH=$MAQAO/sa_analysis
maqao ${MAQAO_SA_PATH}/simd_analyzer.lua --dd <BINARY>:<FUNCTION>
\end{verbatim}

Flag \texttt{--dd} is optional, it assumes \dd is available on the system. When
enabled, the SIMD analyzer uses \dd to translate binary addresses into source
locations, provided the binary was compiled with debugging information included
(typically enabled by specifying the '-g' flag at compile time to the compiler).

% s116
\begin{figure}[h]
  \centering
\includegraphics[width=1\textwidth]{fs116_l47}
\caption{Dependence graph for TSVC s116.}\label{fig:dgs116}
\end{figure}

The listing below is extracted from kernel \texttt{s116} in the TSVC benchmark
suite. Note that since the innermost index loop runs five by five steps at a time, there are no
intra-iteration dependencies for the innermost loop.
\lstset{style=C}
\begin{lstlisting}
/* TSVC s116 kernel */
for (int nl = 0; nl < ntimes*10; nl++) {
        for (int i = 0; i < LEN - 5; i += 5) {
                a[i] = a[i + 1] * a[i];
                a[i + 1] = a[i + 2] * a[i + 1];
                a[i + 2] = a[i + 3] * a[i + 2];
                a[i + 3] = a[i + 4] * a[i + 3];
                a[i + 4] = a[i + 5] * a[i + 4];
        }
        [...]
}
\end{lstlisting}
% s116
\begin{figure}[p]
  \centering
\includegraphics[width=0.70\textwidth]{cfg_s116}
\caption{Control flow graph for TSVC s116.}\label{fig:cfgs116}
\end{figure}

Running the simd module on the kernel produces the following output, as well as
the instruction level dependence graph in \texttt{.dot} format (see
Fig.~\ref{fig:dgs116}), and the control flow graph (see Fig.~\ref{fig:cfgs116}). 
The output indicates the routine being analyzed, the
source language of the routine as indicated in the binary DWARF debugging
information, and the loops detected in the function assembler code. For each
loop entry, the MAQAO assigned loop id and the corresponding source code line
are mentioned. Note that the number of loops found in the binary code may differ
from the number of loops in the source file (in either way, larger or smaller), due to possible code
transformations and optimizations by the compiler, such as loop unrolling,
splitting or even inlining. 

\begin{small}
\begin{verbatim}
analysing: s116
language: C
----------
# Loop entries
# loop 47: tsvc.c:1211
# loop 48: tsvc.c:1209
\end{verbatim}
\end{small}

The module then lists a disassembled text for the detected loops, indicating for
each assembler instruction line the corresponding source code file and line, the
corresponding loop number and nesting, the instruction address and the
disassembled instruction. Loop nest paths are ordered from outermost on the left
to innermost on the right. For instance, \verb|l.48:47| for address
\texttt{0xcd64} indicates that the instruction is both part of~loop 47 and~48
in terms of MAQAO loop ids, and loop 47 is nested in loop~48. SIMD potential is
explored for the innermost loops of the function.

\begin{small}
\begin{verbatim}
- raw instruction listing -
  o tsvc.c:1211 l.48:47 0xcd64: vldr	s15, [r3, #-20] ;
  o tsvc.c:1211 l.48:47 0xcd68: vldr	s14, [r3, #-16] ;
  o tsvc.c:1211 l.48:47 0xcd6c: vmul.f32	s15, s15, s14;
  o tsvc.c:1211 l.48:47 0xcd70: vstr	s15, [r3, #-20] ;
  o tsvc.c:1212 l.48:47 0xcd74: vldr	s15, [r3, #-12] ;
  o tsvc.c:1212 l.48:47 0xcd78: vmul.f32	s14, s14, s15;
  o tsvc.c:1212 l.48:47 0xcd7c: vstr	s14, [r3, #-16] ;
  o tsvc.c:1213 l.48:47 0xcd80: vldr	s14, [r3, #-8] ;
  o tsvc.c:1213 l.48:47 0xcd84: vmul.f32	s15, s15, s14;
  o tsvc.c:1213 l.48:47 0xcd88: vstr	s15, [r3, #-12] ;
  o tsvc.c:1214 l.48:47 0xcd8c: vldr	s15, [r3, #-4] ;
  o tsvc.c:1214 l.48:47 0xcd90: vmul.f32	s14, s14, s15;
  o tsvc.c:1214 l.48:47 0xcd94: vstr	s14, [r3, #-8] ;
  o tsvc.c:1215 l.48:47 0xcd98: vldr	s14, [r3, #0] ;
  o tsvc.c:1215 l.48:47 0xcd9c: vmul.f32	s15, s15, s14;
  o tsvc.c:1215 l.48:47 0xcda0: vstr	s15, [r3, #-4] ;
  o tsvc.c:1215 l.48:47 0xcda4: add	r3, r3, #20 ;
  o tsvc.c:1210 l.48:47 0xcda8: cmp	r3, r4;
  o tsvc.c:1210 l.48:47 0xcdac: bne	cd64 <s116+54>;
  o tsvc.c:1217 l.48    0xcdb0: movw	r3, #27808 ;
    [...]
  o tsvc.c:1209 l.48    0xce04: b	cd64 <s116+54>;
----------
\end{verbatim}
\end{small}

Possible issues preventing proper simdization include inter-instruction 
dependencies, appearing as dependence cycles. Dependences found in the loop nest 
assembler instructions are displayed in the function's associated dependence 
graph (see Fig.~\ref{fig:dgs116}). Edges in Red correspond to memory index 
computation dependences (instruction paths leading to the generation of an 
address used in a memory reference), while black edges correspond to data 
computation dependencies. The dependence graph confirms that no dependence cycle 
would prevent simdization in this \texttt{s116} loop~47.

\begin{small}
\begin{verbatim}
- circuits analysis - checking whether data dependences are compatible with vectorization
  . l.47 has no dependence cycle
      > loop is vectorizable
\end{verbatim}
\end{small}

However the 5-element memory access strides for each stream are large, and do not immediately
match the preferred vector length of the underlying architecture.

\begin{small}
\begin{verbatim}
- memory stride analysis - checking whether data strides are compatible with vectorization
  . l.47 has references with large or negative index strides
      > memory load(s) with large/negative stride
        . 20 bytes
          . tsvc.c:1211 l.48:47 0xcd64: vldr	s15, [r3, #-20] ;
          [...]
      > memory store(s) with large/negative stride
        . 20 bytes
          . tsvc.c:1211 l.48:47 0xcd70: vstr	s15, [r3, #-20] ;
\end{verbatim}
\end{small}

\paragraph{Extend and customize}

The MAQAO framework is designed as a foundation to build custom binary analysis strategies using the 
building blocks provided by the core services together with the \lua layer. Custom MAQAO analysis 
scripts are written in \lua. They can be executed by specifying the script filename as the first 
argument of the MAQAO executable, while the remaining arguments can be used by the script itself for 
its own purpose. The SIMD analyzer script is meant to serve has an example on how to write custom 
MAQAO scripts, and how to access and manipulate objects such as binary files, functions, loops or 
assembly instructions, for instance, from within \lua scripts.

\section{Integration}\label{sec:integration}

This section presents the MAQAO in BOAST integration from an organizational and usage point of view. 
Implementation details will be further discussed in the next section.

\subsection{Big Picture}
\begin{figure}[h]
  \centering
\includegraphics[width=0.8\textwidth]{bigpicture}
\caption{Big-picture of the BOAST-MAQAO interaction flow.}\label{fig:bigpict}
\end{figure}

Figure~\ref{fig:bigpict} shows the big picture of the interaction flow between BOAST and MAQAO. A 
BOAST meta-kernel source file written in the \ruby language is submitted to BOAST. BOAST internals 
are organized as a series of rules or passes, following a scheme similar to a Makefile, to generate 
source files, build them and execute them for performance evaluation and autotuning. MAQAO is 
integrated in this scheme as a specific pass, that may be enabled or disabled on demand. It is called 
once the YAML annotated source file in C or Fortran has been generated and compiled as an autonomous 
executable, to work on the resulting binary.

\subsection{Usage}

Since BOAST integrates a dedicated build pass for MAQAO, using BOAST and MAQAO together requires 
enabling this specific pass by positioning the environment variable \verb|MAQAO_PASS| to \texttt{TRUE}, as 
well as defining the variable \verb|MAQAO_PATH| to the MAQAO installation directory. Then, either 
\verb|MAQAO_WRAP_TMPL_F| and/or \verb|MAQAO_WRAP_TMPL_C| must be defined to specify a template wrapper source file, used 
to call the kernel routine, and necessary for building an autonomous executable from the generated kernel. The wrapper 
template should provide memory allocation and data initialization inside an \verb|@@INIT@@| 
function, together with a call from that \verb|@@INIT@@| function to the \verb|@@KERNEL@@| kernel 
function. The \verb|@@INIT@@| and \verb|@@KERNEL@@| placeholders in the template are then 
substituted with the proper function names by BOAST at run-time, since such functions names are 
generated dynamically. An example, minimalistic wrapper file in C is given below for calling a 
MagicFilter1D kernel routine from MontBlanc-2 application BigDFT.

\lstset{style=C}
\begin{lstlisting}
#include <stdlib.h>
#include <stdint.h>

void @@KERNEL@@(uint32_t, uint32_t,
                uint32_t, uint32_t,
                double *, double *);

void @@INIT@@(void) {
  uint32_t n = 32;
  uint32_t ndat = 32*32;
  uint32_t nx = 32;
  uint32_t ny = 32;
  double *x = calloc(nx*ndat,sizeof(double));
  double *y = calloc(ny*ndat,sizeof(double));
  @@KERNEL@@(n,ndat,nx,ny, x, y);
  free(y);
  free(x);
}

int main() {
  @@INIT@@();
  return 0;
}
\end{lstlisting}

An example \verb|boast_maqao.sh| shell script is shipped within the MAQAO tree, in directory 
\verb|/scripts|, to help set the required environment variables before the call to BOAST. Regarding 
the compilation flags, \texttt{CFLAGS} and/or \texttt{FCFLAGS} should specify compiling for ARM 
architecture and NEON floating point unit, and enable debugging informations encoded in compliance with 
the DWARF-2 format; other debugging information formats may not be recognized or decoded properly. With 
well known compilers GNU GCC and GFortran, the corresponding flags should be
\verb|-marm -mfpu=neon -gdwarf-2|.

The MAQAO tree also ships with a \verb|maqao_from_boast.sh| script, also located in 
\verb|MAQAO/scripts|, which is called by default when BOAST reaches the MAQAO pass during the build 
process. This script serves both as a default MAQAO analysis sequence for when cooperating with 
BOAST, and as an example about how to get relevant data from BOAST about the kernel being studied. 
An alternate \verb|maqao_from_boast.sh| script can be used instead, by pointing the 
\verb|MAQAO_SCRIPT| environment variable to it.

\section{Implementation}\label{sec:implementation}

This section describes the ``MAQAO-in-BOAST'' integration in more details, discussing data exchange 
using YAML structured data, binary-level issues regarding kernel generation and instrumentation.

\subsection{Data Exchange}

%\begin{itemize}
%  \item Requirements
%  \item YAML structured data
%  \item BOAST --> MAQAO
%  \item MAQAO --> BOAST
%\end{itemize}

During the joint BOAST and MAQAO processing, both frameworks need to be able to exchange 
informations. BOAST generates optimized source kernels from \ruby-written meta kernels. The generated 
source is then compiled using some external compiler, and MAQAO eventually gets called to explore the 
resulting binary. Thus, some information channel is needed to carry details about the kernel source 
generation and optimizations, in such a way that it can be related to assembly instructions and 
control structures (e.g. loops) found in the disassembled binary. Debugging information generated by 
compilers enables associating assembly instruction addresses to source code lines. Thus, annotating 
the source code constructs with special comments provides the communication channel needed.

To enable information transfer flexibility, while keeping the parsing straightforward, BOAST and 
MAQAO use the YAML structured data language~\cite{yaml:2017}. The listing extract below shows an 
example of two Fortran loops prepended with YAML comments. In the case of OpenMP loops such as the 
first loop below, the YAML block appears before the OpenMP pragma. The YAML annotation indicates 
informations such as the code element identification (e.g. loop number), and relevant element 
parameters (iterations, bounds, steps, directions, etc. in the case of loops).

% moved to an external file to work-around an issue with VIM LaTeX mode.
\input{f90_loop.tex}

In return, MAQAO's simd analyzer module can output YAML-formatted information
as well. The output indicates informations such as the DWARF-side
identifications and the actual symbol name of the function, which may differ from
its DWARF counterpart, due, for instance, to mangling such as the appended
trailing underscore for Fortran symbols, as can be seen below.

\begin{verbatim}
---
d_sym8_md_p_10_ld_u1_v1_1_t_t_t_:
  maqao_dwarf_file: /tmp/d_sym8_md_p_10_ld_u1_v1_1_t_t_t20170108_29558_1ujhbcj.f90
  maqao_dwarf_func: d_sym8_md_p_10_ld_u1_v1_1_t_t_t
  maqao_symbol: d_sym8_md_p_10_ld_u1_v1_1_t_t_t_
  maqao_dwarf_language: fortran
  maqao_loop_index:
    '1': For7
    '0': For3
    '3': For5
    '2': For3
    '4': For0
  maqao_dwarf_data: true
[...]
\end{verbatim}

The \verb|loop_index| entry matches MAQAO's loop numbering with BOAST loop
numbering. The \verb|dwarf_data| boolean entry indicates whether the DWARF
debugging informations were properly found and decoded. Loops entries, below, detail
findings and possible simd-oriented issues regarding the binary code produced.
They list potential issues such as memory access strides, data dependency
cycles, complex branching.

\begin{verbatim}
[...]
  For0:
    maqao_loop_id: '4'
    maqao_sa_innermost: true
    maqao_sa_nb_paths: 4
    maqao_sa_large_store_stride: false
    maqao_sa_large_load_stride: false
    maqao_sa_dependence_cycle: bad_cycle
[...]
\end{verbatim}

\subsection{Kernel generation}

Our MAQAO port on ARM requires the resulting kernel binary to be an executable.
Binary patching and instrumentation is not supported at this time for position
independent codes on the ARM architecture, such as code generated for shared
objects. Yet, by default, BOAST generates binaries from the source meta-kernel
as shared objects, and loads them directly inside BOAST's own \ruby process.
Thus, BOAST has been modified to generate "non position-independent" object
files as well, and link them with a specialized wrapper to produce and
executable code.

The wrapper is specialized from a generic template supplied by
the programmer to initialize the data environment and launch the kernel
routine. The template wrapper is assumed to provide a routine named
\verb|@@INIT@@|, and either a function \texttt{main} (for C language) or a
program body (for Fortran language). The \texttt{main} function or program body
must call \verb|@@INIT@@|, which itself must call an external routine named
\verb|@@KERNEL@@|. The \verb|@@INIT@@| and \verb|@@KERNEL@@| placeholders in the 
template are then
substituted with the dynamically generated names by BOAST, before building the
executable. Each new kernel instance gets its own unique routine name (which is 
necessary for loading multiple instances of the kernel in the \ruby process 
without name collision), which implies going through this specialization 
process. Future versions of BOAST may instead support generating the whole 
wrapper, and communicate parameters from the main BOAST process to externally 
launched kernel executables using some \ruby serialization/de-serialization 
mechanisms.

\subsection{Kernel instrumentation}

Kernel instrumentation at the binary code level is realized by patching the 
compiled instructions, that is, by moving code blocks and inserting calls to 
external probe functions. The resulting patched binary must still be a valid 
executable file, for the operating system's dynamic loader \verb|ld.so| to be 
able to load and launch it properly. For that, it must be compliant both with 
the generic UNIX System~V application binary interface (ABI), which specifies 
requirements such as the binary file layout (ELF format), sectioning, 
segmentation, constraints and invariants, and with the ARM-specific addenda to 
the ABI. Sections, sections' naming have to follow conventions, such that the 
\verb|.madras| section added by MAQAO's Madras module to contain moved and new 
code blocks has to be accompanied with a \verb|.madras.plt| Procedure Linkage 
Table section, to hold indirection entries towards external routines, and more generally 
to dynamic symbols. Such procedure branching entries branch to an indirect 
address relocation entry computed from the program counter and some constants. 
The relocation entry is updated at run-time by the dynamic linker \verb|ld.so|. 
It initially points a dynamic linker routine to load the corresponding symbol's 
object on the first call to the routine. After the first call, the relocation 
entry is updated with the actual corresponding routine, such that the PLT entry 
instruction sequence now branches directly into the right code. Consequently, 
the PLT entries
are assumed to follow a specific layout and sequence of instructions to build 
the actual target jump address for the entry, taking into account the 
constraints of the architecture in expressing assembly instruction constants. 
The example below shows an excerpt of such PLT entries computing relocation 
entry addresses from the \verb|$pc| register and suitable constants, using 
\verb|$ip| (the instruction pointer) as an intermediate accumulator.

\begin{footnotesize}
\begin{verbatim}
   > Disassembly of section .madras.plt:
   >
   > 0055a044 <.madras.plt>:
      # entry 1:
   >   55a044: e3a0ca08 mov     ip, #32768      ; 0x8
   >   55a048: e59cc440 ldr     ip, [ip, #1088] ; 0x4
   >   55a04c: e5bcf038 ldr     pc, [ip, #56]!  ; 0x3
      # entry 2:
   >   55a050: e3a0ca08 mov     ip, #32768      ; 0x8
   >   55a054: e59cc440 ldr     ip, [ip, #1088] ; 0x4
   >   55a058: e5bcf03c ldr     pc, [ip, #60]!  ; 0x3
      [...]
\end{verbatim}
\end{footnotesize}

All new assembly code blocks and rewritten code blocks are inserted in the new 
binary in an instruction block named \verb|@_patchmov_@|, itself placed in the 
newly created \verb|.madras| section. Jumps from the initial code into new 
routines or rewritten codes are inserted directly at their initial location in 
the binary. Due to the adding and possibly removal of binary code, the size of 
the new binary, the size of the ELF sections (laying out the linker view of the 
ELF file) and the size of the ELF segments (laying out the program view of the 
ELF executable in terms of virtual addresses) may have to be shifted and 
resized. This itself may affect reference offsets for fields and structures 
internal to the binary. Consequently, Madras collects all such offsets while 
disassembling the binary code, which are then updated at the end of the patching 
process, once the new sectioning and segmentation layout is known.

Madras' binary patching capabilities is then used by MAQAO's instrumentation 
code in the Memory module to insert accounting probes inside the targeted kernel 
routine, for each assembly instruction resulting in a memory read or memory 
write. Instrumenting \verb|$pc|relative memory references is however not 
supported on the ARM architecture at this time. Example below shows a diff 
between an uninstrumented binary listing fragment and the corresponding 
instrumented assembly code. Instruction \verb|vldr s14, [r1]| at address 
\texttt{0xbe78} (and other memory referencing instructions as well, such as the 
next one) is replaced by a branch to an inserted instruction block generically 
named \verb|@_patchmov_@|, generated by Madras to perform the memory access 
accounting.
\begin{footnotesize}
\begin{verbatim}
...
be78: ed917a00 vldr    s14, [r1]             | be78: ea15387a b       55a068 <@_patchmov_@>
be7c: ed537a01 vldr    s15, [r3, #-4]        | be7c: ea153899 b       55a0e8 <@_patchmov_@+
be80: ee777a27 vadd.f32        s15, s14, s15   be80: ee777a27 vadd.f32        s15, s14, s15
be84: ee171a90 vmov    r1, s15                 be84: ee171a90 vmov    r1, s15
...
\end{verbatim}
\end{footnotesize}

The assembly fragment below shows part of the \verb|@_patchmov_@| block inserted 
by Madras. This block, residing in the newly created \texttt{.madras.code} ELF 
section in the executable file, is immediately preceded by another newly created 
section named \texttt{.madras.plt} containing the corresponding Procedure 
Linkage Table (PLT) storing the procedure entries for the indirect jumps into 
the MAQAO Trace Library routines.

\begin{footnotesize}
\begin{verbatim}
...
   >
   > Disassembly of section .madras.plt:
   >
   > 0055a044 <.madras.plt>:
   >   55a044: e3a0ca08 mov     ip, #32768      ; 0x8
   >   55a048: e59cc440 ldr     ip, [ip, #1088] ; 0x4
   >   55a04c: e5bcf038 ldr     pc, [ip, #56]!  ; 0x3
   >   55a050: e3a0ca08 mov     ip, #32768      ; 0x8
   >   55a054: e59cc440 ldr     ip, [ip, #1088] ; 0x4
   >   55a058: e5bcf03c ldr     pc, [ip, #60]!  ; 0x3
   >   55a05c: e3a0ca08 mov     ip, #32768      ; 0x8
   >   55a060: e59cc440 ldr     ip, [ip, #1088] ; 0x4
   >   55a064: e5bcf040 ldr     pc, [ip, #64]!  ; 0x4
   >
   > Disassembly of section .madras.code:
   >
   > 0055a068 <@_patchmov_@>:
   >   55a068: e52d0004 push    {r0}            ; (st

   >   55a0a8: e10f0000 mrs     r0, CPSR
   >   55a0ac: e92d47ff push    {r0, r1, r2, r3, r4, 
   >   55a0b0: ed2d8b10 vpush   {d8-d15}
   >   55a0b4: e24dd014 sub     sp, sp, #20
   >   55a0b8: e3000007 movw    r0, #7
   >   55a0bc: e1a02001 mov     r2, r1
   >   55a0c0: e52d2004 push    {r2}            ; (st
   >   55a0c4: e49d1004 pop     {r1}            ; (ld
   >   55a0c8: ebffffe0 bl      55a050 <__bss_end__+0
   >   55a0cc: e28dd014 add     sp, sp, #20
   >   55a0d0: ecbd8b10 vpop    {d8-d15}
   >   55a0d4: e8bd47ff pop     {r0, r1, r2, r3, r4, 
   >   55a0d8: e12ff000 msr     CPSR_fsxc, r0
   >   55a0dc: e49d0004 pop     {r0}            ; (ld
   >   55a0e0: ed917a00 vldr    s14, [r1]
   >   55a0e4: eaeac764 b       be7c <s111+0x60>
...
\end{verbatim}
\end{footnotesize}

The job of the code inserted in \verb|@_patchmov_@| is basically to:
\begin{enumerate}
\item \texttt{55a068..55a0b4:} Save the current program state (registers);
\item \texttt{55a0c8..55a0c8:} Call the relevant MTL accounting routine with the 
memory address of the instrumented memory reference, register \texttt{r1} here, 
in the case of instruction \texttt{0xbe78}, by jumping to the corresponding PLT 
entry and from there to the actual accounting routine;
\item \texttt{55a0cc..55a0dc:} Restore the program registers;
\item \texttt{55a0e0:} Execute the original, moved memory referencing 
instruction \verb|vldr s14, [r1]|;
\item \texttt{55a0e4:} Branch back to the main program at address 
  \texttt{0xbe7c}, immediately following the instrumented location 
  \texttt{0xbe78}, to continue program execution (which fortuitously happens to 
  be a memory reference also, and is thus instrumented as well).
\end{enumerate}

\subsection{Kernel analysis framework}

%\begin{itemize}
%  \item Principle
%  \item C low-level framework
%  \item Lua high-level framework
%  \item SIMD analyzer example
%\end{itemize}

The MAQAO Framework is organized as a C-language low-level set of core services. 
Since coordinating these services together in a custom C analysis code would be 
cumbersome, a higher level \lua language layer is built on top of this core set 
of C services, to make the whole framework scriptable.

The low level C services include the following libraries:
\begin{itemize}
  \item \texttt{libmdisass} provides access to disassembling services and binary 
    structure discovery (symbol boundaries, branch tables, etc.)

  \item \texttt{libmpatch} provides access to binary modification operations 
    such as instrumentation, block moves, and new code generation. In particular, 
    it coordinates the process of applying a set of transformation operations on 
    some loaded ELF binary, by calling \texttt{libmtroll} services as needed.

  \item \texttt{libmtroll} provides access to very low level services for ELF 
    structure parsing, modification and re-generation services. In this respect, 
    it is in charge for actions such as ELF section decoding, symbol tables 
    processing, as well as performing low level update operations as the result 
    of binary patching by \texttt{libmpatch} such as symbol insertions, section reordering/renumbering, and 
    memory offset updates.

  \item \texttt{libmaqao} provides means to access the servicing libraries 
    above, and embeds a \lua interpretor so as to be able to execute high-level 
    scripts written in the \lua language. The main advantage of \lua, beyond its 
    straightforward, minimalistic syntax, is to offer a reasonably compact 
    interpretor, small enough to be distributed together with MAQAO. The 
    \texttt{libmaqao} library also implements all the bindings needed to make 
    the low level C services usable from \lua scripts. For that, it implements a 
    set of object interfaces for each common assembly element such as 
    assembler instructions, basic instruction blocks, loops and functions. It also 
    provides management objects such as the project (basically representing a 
    MAQAO session) and the assembler files, and some objects to manipulate common 
    assembly parameters such as instruction operands (register~/ memory~/ 
    immediate value, etc.), labels or bit vectors. Finally, it also comes with a 
    comprehensive set of generic data structure implementations (graphs, tree, 
    etc.) that can readily be used in user \lua scripts.

\end{itemize}

As detailed in the MAQAO usage section above, passing a user-written \lua script 
as the first argument to the MAQAO command loads and executes this script using 
the embedded \lua interpretor, with immediate access to all of MAQAO's own \lua objects and 
routines, which programmers may use to tailor their own custom binary analysis 
scripts. The simd analyzer script, available in MAQAO's \verb|sa_analysis/| 
directory, serves as an example on how to write such custom analysis strategies.

After importing its own custom sub-modules, the simd analyzer sets a MAQAO 
project up for the session, and initializes it by loading the kernel binary 
passed as command line argument inside the project. It also optionally builds a call graph 
(as a \verb|.dot| file) of the binary, for the programmer to get a synthetic 
view of the program flow in terms of function calls. If \dd is available on the 
system, the script also attempts to load and decode debugging informations from 
the binary, and builds a mapping of assembly instruction addresses to source 
code locations.

Once these preliminary steps are completed, the scripts explores the targeted 
function for loops, basic instruction blocks and individual instructions, to 
discover loop nesting paths for each instruction. If debugging informations are 
available, and if the source code is still accessible on the filesystem, the loop 
neighborhood is explored in the source code file to discover possible YAML-format 
comment annotations, in C or in Fortran language, according to language 
identification found in the DWARF debugging information for the routine. In case 
some YAML enriched comment is found, it is decoded on the fly. A post-processed 
trace file may also optionally be loaded if available, in which case dynamic 
memory reference dependencies and access patterns are loaded and analyzed to 
discover possible execution-related simdization hindrance or reduced efficiency.

Inter-instruction register dependences are discovered from the disassembled 
instructions, while distinguishing whether such dependence edges are carried 
through a register or an index. The resulting dependence graph is explored to 
discover dependence cycles that may prevent simdization (false positives are 
possible, however, since MAQAO's detected cycles may be the result of the 
compiler register allocation algorithm, while the initial source code algorithm 
may or may not exhibit the dependence cycle as well). A specific attention is 
applied to dependence cycles on floating point instruction registers, which are 
more likely to be data access pattern-related, and thus may be caused by source 
level inter-iteration dependences. The weight of the dependence cycle is 
computed from the sum of the dependence distances in the cycle. It is used to 
detect whether some iterations may be performed in parallel using simdization, 
or the instruction dependence flow is incompatible due to an unit-weighted cycle 
(each loop iteration depends on the result of the iteration immediately 
preceding it) or unknown/unrecognized dependences are found in the cycle. A special case is 
distinguished for reductions, where a unit-weighted cycle is found, and all
instructions in the cycle are identically named (e.g. a sequence of additions, 
for instance, accumulating some iteration results in the same register). In that 
case, simdization may be considered using some parallel tree-based reduction 
scheme.

Register-level circuits also are analyzed to infer inter-iteration access 
strides from the binary instruction layout and constant register increments 
found in the code. This information is reported to the user when access strides 
look too large to accommodate simdization, suggesting that the corresponding data 
structure is too sparse, too irregular, or not accessed through its innermost, 
contiguous dimension (as would for instance be the case for a column-major 
multi-dimensioned array being accessed as a row-major array, or conversely). 
Likewise, a negative stride would suggest to consider loop reversal on the 
source side, if applicable. Finally, a dependence graph (also as a \verb|.dot| 
file) is generated to display the memory reference computation flows and data 
computation flows, to give a visual insight of the data dependence edges found 
by MAQAO in the binary kernel. It is accompanied with a control flow graph 
showing the connected components found in the function body, which helps to localize 
loops within the structure of the function. The shading increases according to 
the nesting level of the connected component.

\section{Testcases examples}\label{sec:examples}

This section presents some tests cases using the MAQAO-in-BOAST framework. We 
first use a very basic vector addition kernel to get an overview of the multiple 
files, graphs and outputs being generated from the initial meta kernel. The 
second example is a kernel extracted from 
BigDFT~\cite{genovese:bigdft:jcp:2008}, an ab-initio nanosimulation code written 
at CEA, and part of Project Mont-Blanc~2's target applications.

  \subsection{Vector Addition}

  The core part of the \ruby script making the \verb|vector_add| meta kernel is 
  shown below. It uses BOAST calls to build an abstract representation of the 
  kernel. This abstract representation is then used to instantiate kernel 
  versions as needed. The routine below can be used for generating both C and 
  Fortran instantiations. It can also generate accelerator-enabled CUDA or 
  OpenCL routines, which is out of scope for the present document, however.
  
\begin{lstlisting}[style=BOAST]
def vector_add
  n = Int("n",:dir => :in)
  a = Real("a",:dir => :in, :dim => [ Dim(n)] )
  b = Real("b",:dir => :in, :dim => [ Dim(n)] )
  c = Real("c",:dir => :out, :dim => [ Dim(n)] )
  p = Procedure("vector_add", [n,a,b,c]) {
    decl i = Int("i")
    expr = c[i] === a[i] + b[i]
    if (get_lang == CL or get_lang == CUDA) then
      pr i === get_global_id(0)
      pr expr
    else
      pr For(i,0,n-1) {
        pr expr
      }
    end
  }
  return p.ckernel
end
\end{lstlisting}

One possible instantiation is the C-language listing below. It is deliberately 
simplistic for the purpose of exemplification. Yet, one can see both the 
function and the loop following the C syntax. The loop is preceded by a C-style 
block of comments containing a YAML data block, as explained in the 
implementation section above. 

\begin{lstlisting}[language=C]
void vector_add(const int32_t n, const float * a, const float * b, float * c){
  int32_t i;
/* --- */
/* For1: */
/*   :iterator: i */
/*   :first: 0 */
/*   :last: n - (1) */
/*   :step: 1 */
/*   :operator: <= */
  for (i = 0; i <= n - (1); i += 1) {
    c[i] = a[i] + b[i];
  }
}
\end{lstlisting}

BOAST's building passes then generate binaries from the C-source kernel, both as 
a shared object that can be loaded within the BOAST \ruby process, and as an 
executable, on which the MAQAO pass is called, if enabled, which is the case by 
default if BOAST is called using the shipped \verb|boast_maqao.sh| shell script.

MAQAO first outputs general details about the executable and routine to be 
processed, as a sanity check to verify that the binary file can be loaded and 
parsed successfully.

\begin{verbatim}
analysing: vector_add
/tmp/vector_add20170114_15910_1mq6zxr.c:5
language: C
\end{verbatim}

\begin{figure}[h]
  \centering
\includegraphics[width=0.8\textwidth]{c_no_fpic}
\caption{Function control flow graph for the generated vector addition kernel, the loop (numbered 0) is in the connected component~\#2.}\label{fig:cfg_vec_add}
\end{figure}

The control flow graph of the kernel function is generated 
(see~\ref{fig:cfg_vec_add}), showing all the connected components found in the 
assembly code. The disassembled section of the binary corresponding to the loop 
is listed for reference.

\begin{verbatim}
# Loop entries
- raw instruction listing -
  o l.0 0x28: ldr       r3, [fp, #-8] ;
  o l.0 0x2c: lsl       r3, r3, #2 ;
  o l.0 0x30: ldr       r2, [fp, #-28] ;
  o l.0 0x34: add       r3, r2, r3;
  o l.0 0x38: ldr       r2, [fp, #-8] ;
  o l.0 0x3c: lsl       r2, r2, #2 ;
  o l.0 0x40: ldr       r1, [fp, #-20] ;
  o l.0 0x44: add       r2, r1, r2;
  o l.0 0x48: vldr      s14, [r2, #0] ;
  o l.0 0x4c: ldr       r2, [fp, #-8] ;
  o l.0 0x50: lsl       r2, r2, #2 ;
  o l.0 0x54: ldr       r1, [fp, #-24] ;
  o l.0 0x58: add       r2, r1, r2;
  o l.0 0x5c: vldr      s15, [r2, #0] ;
  o l.0 0x60: vadd.f32  s15, s14, s15;
  o l.0 0x64: vstr      s15, [r3, #0] ;
  o l.0 0x68: ldr       r3, [fp, #-8] ;
  o l.0 0x6c: add       r3, r3, #1 ;
  o l.0 0x70: str       r3, [fp, #-8] ;
  o l.0 0x74: ldr       r3, [fp, #-16] ;
  o l.0 0x78: sub       r2, r3, #1 ;
  o l.0 0x7c: ldr       r3, [fp, #-8] ;
  o l.0 0x80: cmp       r2, r3;
  o l.0 0x84: bge       28 <vector_add+28>;
----------
\end{verbatim}

In the case of this basic loop, the code does not exhibit any inter-iteration 
dependence cycle, as expected. The data dependence graph is consistent with this 
observation (see Fig.~\ref{fig:dg_vec_add}).

\begin{verbatim}
- circuits analysis - checking whether data dependences are compatible with 
  vectorization
  . l.0 has no dependence cycle
      > loop is vectorizable
\end{verbatim}

Moreover, no suboptimal access strides have been detected, both regarding load 
and store instructions, and the loop exhibit a single, straightforward path. The 
loop is therefore trivially simdizable.

\begin{verbatim}
---
vector_add:
  maqao_loop_index:
    '0': For1
  maqao_dwarf_data: true
  maqao_dwarf_language: c
  maqao_dwarf_file: /tmp/vector_add20170114_18346_w2tofy.c
  maqao_dwarf_func: vector_add
  For1:
    maqao_sa_innermost: true
    maqao_sa_nb_paths: 1
    maqao_sa_large_store_stride: false
    maqao_sa_large_load_stride: false
    yaml: For1
    maqao_loop_id: '0'
    maqao_sa_dependence_cycle: none
[...]
\end{verbatim}

Instrumenting and tracing memory accesses in the routine confirms that three 
instructions respectively access three 2-MB arrays in an unidimensional pattern,
with a stride of 4-bytes (the size of C~\texttt{float} elements), as shown in 
the processed trace extract below.

\begin{verbatim}
## Volume for tid = 0 loopid = 0 iid = 4
for i0 = 0 to 2097151
  val 0xb6666008 + 4*i0

## Volume for tid = 0 loopid = 0 iid = 7
for i0 = 0 to 2097151
  val 0xb5e65008 + 4*i0

## Volume for tid = 0 loopid = 0 iid = 8
for i0 = 0 to 2097151
  val 0xb5664008 + 4*i0
\end{verbatim}

\begin{figure}[h]
  \centering
\includegraphics[width=1\textwidth]{fvector_add_l0}
\caption{Dependence graph for the loop 0.}\label{fig:dg_vec_add}
\end{figure}

  \subsection{BigDFT Filter}

  BigDFT is a nanosimulation application designed at CEA to simulate the 
  properties of materials at the atomic level. It is one of the applications to 
  be explored in the context of the Mont-Blanc~2 project.
  It is based on the Density Functional Theory (DFT) and uses a wavelet basis 
  set. As such, it heavily relies on convolution filtering kernels. A family of 
  such kernels have been ported onto BOAST as meta-kernels. We therefore applied 
  the MAQAO-in-BOAST framework to the \texttt{MagicFilter1d} members of that 
  family. The piece of BOAST meta-kernel common to this family of kernels 
  is shown below for references, though most of the actual meta-code is actually defined 
  in sub-modules.

\begin{lstlisting}[style=BOAST]
def MagicFilter1d(filter, optims=GenericOptimization::new)
  conv_operation = GenericConvolutionOperator1d::new(filter, :ld => true, :narr => true, :a_x => true,:a_y=>true, :a => true)
  conv_operation.optimize(optims) if optims

  p, subops = conv_operation.procedure

  kernel = BOAST::CKernel::new

  print_header

  subops.each_value { |op|
    BOAST::pr op
    puts "chosen:"+ op.name
  }
  BOAST::pr p

  kernel.procedure = p
  kernel.cost_function = lambda { |*args| conv_operation.cost(*args) }
  return kernel
end
\end{lstlisting}

A part of one instance of this meta kernel is shown in Fortran below. It has 
been shortened for editing purpose. However, it clearly shows the benefit of 
using BOAST, since working on such kernels ``by hand'' would be tricky and error 
prone. This listing is YAML-annotated on loop structures, in anticipation for 
MAQAO processing. The careful reader may have noticed that the \texttt{For3} 
annotation does not precede a loop statement. This signifies that the 
corresponding loop has been unrolled and inlined. Thus, no loop statement is 
needed on this ``virtual'' loop, in this kernel instance.

\input{mf1d_f90.tex}
\begin{figure}[p]
  \centering
\includegraphics[width=0.90\textwidth]{cfg_bigd_kernel_crop}
\caption{Control flow graph for one instance of MagicFilter1d meta 
kernel.}\label{fig:cfgmf1d}
\end{figure}

Once the MAQAO pass is reached in the building process, the binary analysis 
starts. Five loops are found in the generated binary, as can be seen in the 
identification output below. A cropped version of the huge control graph is also 
shown on Figure~\ref{fig:cfgmf1d}.

\begin{verbatim}
analysing: d_sym8_md_p_10_ld_u1_v1_1_t_t_t_
/tmp/d_sym8_md_p_10_ld_u1_v1_1_t_t_t20170114_19966_r5332h.f90:1
language: Fortran95
---
maqao_dwarf_language: fortran
maqao_dwarf_file: /tmp/d_sym8_md_p_10_ld_u1_v1_1_t_t_t20170114_19966_r5332h.f90
maqao_dwarf_func: d_sym8_md_p_10_ld_u1_v1_1_t_t_t
maqao_dwarf_data: true
maqao_symbol: d_sym8_md_p_10_ld_u1_v1_1_t_t_t_

----------
# Loop entries
# loop 0: d_sym8_md_p_10_ld_u1_v1_1_t_t_t20170114_19966_r5332h.f90:78
# yaml annotations found:
# - generator's loop id: For2
# - loop iterator: i1
# - loop step: 1
# - loop operator: <=
# loop 1: d_sym8_md_p_10_ld_u1_v1_1_t_t_t20170114_19966_r5332h.f90:211
# yaml annotations found:
# - generator's loop id: For6
# - loop iterator: i1
# - loop step: 1
# - loop operator: <=
# loop 2: d_sym8_md_p_10_ld_u1_v1_1_t_t_t20170114_19966_r5332h.f90:145
# yaml annotations found:
# - generator's loop id: For4
# - loop iterator: i1
# - loop step: 1
# - loop operator: <=
# loop 3: d_sym8_md_p_10_ld_u1_v1_1_t_t_t20170114_19966_r5332h.f90:79
# yaml annotations found:
# - generator's loop id: For2
# - loop iterator: i1
# - loop step: 1
# - loop operator: <=
# loop 4: d_sym8_md_p_10_ld_u1_v1_1_t_t_t20170114_19966_r5332h.f90:58
# yaml annotations found:
# - generator's loop id: For0
# - loop iterator: l
# - loop step: 1
# - loop operator: <=
\end{verbatim}

We will not detail all the loops here. However, Loop~\#4 (MAQAO ID) corresponding 
to BOAST's generated Loop \verb|For0| is especially interesting. The loop is 
shown below followed by the corresponding unoptimized (for illustration purpose) 
assembly code output by MAQAO. While the source code of the loop is extremely 
short, the resulting binary is long and complex instead.

\input{mf1d_For0_f90.tex}

\begin{footnotesize}
\begin{verbatim}
  o d_sym8.f90:58 l.4   0x90:	ldr	r3, [fp, #-48] ;
  o d_sym8.f90:58 l.4   0x94:	add	sl, r3, #15 ;
  o d_sym8.f90:58 l.4   0x98:	ldr	r3, [fp, #-208] ;
  o d_sym8.f90:58 l.4   0x9c:	ldr	r8, [r3, #0] ;
  o d_sym8.f90:58 l.4   0xa0:	ldr	sb, [fp, #-48] ;
  o d_sym8.f90:58 l.4   0xa4:	mov	r3, sb;
  o d_sym8.f90:58 l.4   0xa8:	cmp	r8, #0 ;
  o d_sym8.f90:58 l.4   0xac:	blt	d4 <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_+d4>;
  o d_sym8.f90:58 l.4   0xb0:	cmp	r3, #0 ;
  o d_sym8.f90:58 l.4   0xb4:	blt	cc <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_+cc>;
  o d_sym8.f90:58 l.4   0xb8:	mov	r1, r8;
  o d_sym8.f90:58 l.4   0xbc:	mov	r0, r3;
  o d_sym8.f90:58 l.4   0xc0:	bl	0 <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_>;
  o d_sym8.f90:58 l.4   0xc4:	mov	r3, r0;
  o d_sym8.f90:58 l.4   0xc8:	b	108 <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_+108>;
  o d_sym8.f90:58 l.4   0xcc:	add	r3, r3, #1 ;
  o d_sym8.f90:58 l.4   0xd0:	b	f4 <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_+f4>;
  o d_sym8.f90:58 l.4   0xd4:	cmp	r3, #0 ;
  o d_sym8.f90:58 l.4   0xd8:	bgt	f0 <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_+f0>;
  o d_sym8.f90:58 l.4   0xdc:	mov	r1, r8;
  o d_sym8.f90:58 l.4   0xe0:	mov	r0, r3;
  o d_sym8.f90:58 l.4   0xe4:	bl	0 <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_>;
  o d_sym8.f90:58 l.4   0xe8:	mov	r3, r0;
  o d_sym8.f90:58 l.4   0xec:	b	108 <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_+108>;
  o d_sym8.f90:58 l.4   0xf0:	sub	r3, r3, #1 ;
  o d_sym8.f90:58 l.4   0xf4:	mov	r1, r8;
  o d_sym8.f90:58 l.4   0xf8:	mov	r0, r3;
  o d_sym8.f90:58 l.4   0xfc:	bl	0 <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_>;
  o d_sym8.f90:58 l.4   0x100:	mov	r3, r0;
  o d_sym8.f90:58 l.4   0x104:	sub	r3, r3, #1 ;
  o d_sym8.f90:58 l.4   0x108:	mul	r3, r8, r3;
  o d_sym8.f90:58 l.4   0x10c:	rsb	r2, r3, sb;
  o d_sym8.f90:58 l.4   0x110:	lsl	r3, sl, #2 ;
  o d_sym8.f90:58 l.4   0x114:	sub	r1, fp, #36 ;
  o d_sym8.f90:58 l.4   0x118:	add	r3, r1, r3;
  o d_sym8.f90:58 l.4   0x11c:	str	r2, [r3, #-160] ;
  o d_sym8.f90:57 l.4   0x120:	ldr	r3, [fp, #-48] ;
  o d_sym8.f90:57 l.4   0x124:	cmp	r3, #14 ;
  o d_sym8.f90:57 l.4   0x128:	moveq	r3, #1 ;
  o d_sym8.f90:57 l.4   0x12c:	movne	r3, #0 ;
  o d_sym8.f90:57 l.4   0x130:	ldr	r2, [fp, #-48] ;
  o d_sym8.f90:57 l.4   0x134:	add	r2, r2, #1 ;
  o d_sym8.f90:57 l.4   0x138:	str	r2, [fp, #-48] ;
  o d_sym8.f90:57 l.4   0x13c:	cmp	r3, #0 ;
  o d_sym8.f90:57 l.4   0x140:	bne	148 <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_+148>;
  o d_sym8.f90:57 l.4   0x144:	b	90 <d_sym8_md_p_10_ld_u1_v1_1_t_t_t_+90>;

\end{verbatim}
\end{footnotesize}

This means that, while the three other loops are readily 
simdizable (MAQAO ID Loop~\#0 is not considered, because not innermost), Loop~\#4 instead exhibits issues in terms of both code path complexity 
(4~different execution paths founds in the loop), and suboptimal strides.

\begin{verbatim}
- circuits analysis - checking whether data dependences are compatible with vectorization
  . l.1 has no dependence cycle
      > loop is vectorizable
  . l.2 has no dependence cycle
      > loop is vectorizable
  . l.3 has no dependence cycle
      > loop is vectorizable
  . l.4 has no dependence cycle
      > loop is vectorizable
- memory stride analysis - checking whether data strides are compatible with vectorization
  . l.4 has references with large or negative index strides
- control flow analysis
  . l.4 has 4 different execution paths
      > complex control flow hinders vectorization. Use versioning, loop splitting or masks
\end{verbatim}

The output of the memory reference instrumentation trace, however, shows that 
the actual behaviour of this loop at run-time, in terms of memory access patterns, is 
much smoother than inferred from the structure of the assembly instructions flow alone.

\begin{small}
\begin{verbatim}
Info: ## Volume for tid = 0 loopid = 4 iid = 475
Info: Instance 0
for i0 = 0 to 29
  val 0xbea47318 + 4*i0
Info: ## Volume for tid = 0 loopid = 4 iid = 476
Info: Instance 0
for i0 = 0 to 29
  val 0xbea473ac
  [...]
Info: ## Volume for tid = 0 loopid = 4 iid = 480
Info: Instance 0
for i0 = 0 to 29
  val 0xbea4730c
Info: ## Volume for tid = 0 loopid = 4 iid = 481
Info: Instance 0
for i0 = 0 to 29
  val 0x9ca0
Info: ## Volume for tid = 0 loopid = 4 iid = 482
Info: Instance 0
for i0 = 0 to 29
  val 0xbea473ac
\end{verbatim}
\end{small}

The static analysis view and the dynamic view extracted from memory access 
collection trace are therefore complementary in exploring the actual quality and 
behaviour of the produced assembly code.


\section{Conclusion and Future Works}\label{sec:conclusion}

This document presented the purpose, process and realization of the integration 
of the MAQAO binary code quality analysis framework together with BOAST, a 
computing kernel generator and optimizer based on an abstract, 
meta-representation of kernel procedures. The report discussed the 
complementarity of the two frameworks, detailed there respective characteristics 
and usage, and proposed a general organization for a combined MAQAO-in-BOAST 
composite framework. After presenting design choices and implementations details 
such as the data channel using specially formatted source code comments, or the 
expected binary format and constraints, examples of use where given on a 
micro-kernel and a kernel from the BigDFT application.

On going works is now dedicated to make both environment able to cooperate in a 
more automatized manner and to enrich the scope of MAQAO analyses on ARM 
architectures with the context of BOAST in mind. The source code wrapper needed 
to build executable versions of the kernels for MAQAO processing could be 
generated automatically, which would not be much more convenient, but would 
allow BOAST to transfer parameters to the kernel before execution. Moreover, 
exploring data layout issues and hinting, on which compilers have little 
control, would allow to return more relevant feedback to BOAST and improve the 
overall optimization process. Since BOAST has the ability to annotate not only 
loops but any abstract syntactical tree (AST) element, MAQAO would then have the 
opportunity to guide its own data layout analysis, and also to confront findings 
with accurate information right from the source code generator.

\bibliographystyle{plain}
\bibliography{d5.11}

\end{document}


% vim: set spell ft=tex fo=aw2t expandtab sw=2 tw=100:
